---
title: "Zillow Model Predictions"
author: "Liz Vincent"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---
## Models

### Predict the Mean
```{r predict_mean}
MAE<-NA

for(i in 1:10){
  set.seed(i)
  rows<-sample(1:nrow(properties),nrow(properties))
  scrambled_properties<-properties[rows,]
  split<-round(nrow(properties) * 0.80)
  train<-scrambled_properties[1:split,]
  test<-scrambled_properties[(split+1):nrow(properties),]
  MAE[i]<-sum(abs(mean(train$logerror) - test$logerror))/nrow(test)
}
mean(MAE)
sum(abs(mean(properties$logerror) - properties$logerror))/nrow(properties)
```

### Predict the Median
```{r predict_median}
MAE<-NA

for(i in 1:10){
  set.seed(i)
  rows<-sample(1:nrow(properties),nrow(properties))
  scrambled_properties<-properties[rows,]
  split<-round(nrow(properties) * 0.80)
  train<-scrambled_properties[1:split,]
  test<-scrambled_properties[(split+1):nrow(properties),]
  MAE[i]<-sum(abs(median(train$logerror) - test$logerror))/nrow(test)
}

mean(MAE)
sum(abs(median(properties$logerror) - properties$logerror))/nrow(properties)
```

### Linear Models
```{r linear_models}
data<-properties[,names(properties) %in% c("lotsizesquarefeet","calculatedfinishedsquarefeet","bathroomcnt","yearbuilt","logerror","bedroomcnt","latitude","longitude","roomcnt")]

for(i in 1:ncol(data)){
  data[is.na(data[[i]]),i]<-median(na.omit(data[,i]))
}

scaled_data<-scale(data[,!names(data) == "logerror"],center=T, scale=T)

data<-cbind(data$logerror, scaled_data)

data_together<-cbind(data,data_missing[,!names(data_missing) %in% c("parcelid","logerror")])
```

```{r glmnet}
myGrid <- expand.grid(
  alpha = 0.03,
  lambda = 0.04
)

set.seed(123)

model.glmnet <- train(
  logerror~.,
  data,
  method = "glmnet",
  tuneGrid = myGrid,
  metric = "MAE",
  trControl = trainControl(
  method = "cv",
  number = 10,
  verboseIter = T
  )
)

pred<-predict(model.glmnet,data)

glmnet_preds<-(cbind(pred,properties$logerror))
glmnet_preds<-as.data.frame(glmnet_preds)
names(glmnet_preds)<-c("pred","logerror")

ggplot(glmnet_preds,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(glmnet_preds$pred - glmnet_preds$logerror))/nrow(glmnet_preds)
#0.069247

glmnet_fmla <- coef(model.glmnet$finalModel, model.glmnet$bestTune$lambda)


myGrid <- expand.grid(
  alpha = 0.275,
  lambda = 0.005
)

set.seed(123)

model.glmnet_together<-train(
  logerror~.,
  data_together,
  method = "glmnet",
  tuneGrid = myGrid,
  metric = "MAE",
  trControl = trainControl(
  method = "cv",
  number = 10,
  verboseIter = T
  )
)

pred<-predict(model.glmnet_together,data_together)

glmnet_together_preds<-(cbind(pred,properties$logerror))
glmnet_together_preds<-as.data.frame(glmnet_together_preds)
names(glmnet_together_preds)<-c("pred","logerror")

ggplot(glmnet_together_preds,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(glmnet_together_preds$pred - glmnet_together_preds$logerror))/nrow(glmnet_together_preds)
#0.06918523

glmnet_together_fmla <- coef(model.glmnet_together$finalModel, model.glmnet_together$bestTune$lambda)
```

```{r ranger}
tuningGrid <- data.frame(mtry = 2, splitrule = "extratrees" )

#mtry = c(2,5,8)

set.seed(123)

model.ranger<-train(
  logerror~.,
  data,
  method="ranger",
  tuneGrid = tuningGrid,
  trControl=trainControl(
    method="cv",number=10,
    verboseIter=T
  )
)
# don't need center or scale on tree-based models, median imputation is fine

pred<-predict(model.ranger,data)

forest_preds<-(cbind(pred,properties$logerror))
forest_preds<-as.data.frame(forest_preds)
names(forest_preds)<-c("pred","logerror")

ggplot(forest_preds,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(forest_preds$pred - forest_preds$logerror))/nrow(forest_preds)
#0.05604133
```

```{r}
set.seed(123)

model.ranger2<-train(
  logerror~.,
  data_together,
  method="ranger",
  trControl=trainControl(
    method="cv",number=10,
    verboseIter=T
  )
)

pred<-predict(model.ranger2,data_together)

forest_preds_2<-(cbind(pred,properties$logerror))
forest_preds_2<-as.data.frame(forest_preds_2)
names(forest_preds_2)<-c("pred","logerror")

ggplot(forest_preds_2,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(forest_preds_2$pred - forest_preds_2$logerror))/nrow(forest_preds_2)
#0.0693135
```

```{r}
tuningGrid <- data.frame(mtry = 3, splitrule = "extratrees" )
  
set.seed(123)

model.ranger3<-train(
  logerror~.,
  data_together,
  method = "ranger",
  metric = "MAE",
  tuneGrid = tuningGrid,
  trControl = trainControl(
    method="cv",
    number = 10,
    verboseIter = T
  )
)

pred<-predict(model.ranger3,data_together)

forest_preds_3<-(cbind(pred,properties$logerror))
forest_preds_3<-as.data.frame(forest_preds_3)
names(forest_preds_3)<-c("pred","logerror")

ggplot(forest_preds_3,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(forest_preds_3$pred - forest_preds_3$logerror))/nrow(forest_preds_3)
#0.06644709
```
