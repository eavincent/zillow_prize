---
title: "Zillow Project Exploratory Data Analysis"
author: "Liz Vincent"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F,message = F)

packages<-c("data.table","corrplot","dplyr","ggplot2","magrittr","stringi","stringr","rebus","gridExtra","reshape2","ggmap","tidyr","caret","xgboost","Matrix","ranger","ggcorrplot")

for (i in packages){
  if(!require(i,character.only = T,quietly=T,warn.conflicts = F)){
    install.packages(i)
  }
  require(i,character.only = T,quietly=T,warn.conflicts = F)
}

properties_2016<-read.csv("properties_2016.csv",stringsAsFactors = F)  # This takes a while...~3 million rows, 58 columns
properties_2017<-read.csv("properties_2017.csv",stringsAsFactors = F)

factor_vars <- str_subset(names(properties_2016),pattern="id")
factor_vars <- c(factor_vars,"fips","propertycountylandusecode","propertyzoningdesc","rawcensustractandblock","censustractandblock")
properties_2016[,factor_vars]<-lapply(properties_2016[,factor_vars],factor)
properties_2016$parcelid<-as.character(properties_2016$parcelid)
properties_2017[,factor_vars]<-lapply(properties_2017[,factor_vars],factor)
properties_2017$parcelid<-as.character(properties_2017$parcelid)

train_2016<-read.csv("train_2016_v2.csv")
train_2017<-read.csv("train_2017.csv")


label<-c("Framing Type","Perimeter Living Area Sqft.","Basement Sqft.","Type of Floors in Multi-Story House","Yard Building Sqft.","Fireplace, Y/N","Architecture Style","Construction Material","Unfinished and Finished Sqft.","Type of Deck","Pool Sqft.","Spa or Hot Tub, Y/N","Pool with Spa or Hot Tub, Y/N","Tax Delinquency, Y/N","Year of Tax Delinquency","Spa or Hot Tub, Y/N","Patio Sqft.","Total Sqft.","First Floor Living Area Sqft.","First Floor Living Area Sqft.","No. Fireplaces","No. 3/4 Baths","Pool without Spa or Hot Tub, Y/N","No. Pools","No. Stories","Type of Air Conditioning","No. Garages","Garage Sqft.","Neighborhood ID","Type of Heating System","Building Condition","No. Units","Lot Sqft.","Total Finished Living Area Sqft.","City ID","Total No. Baths","No. Full Baths","Year Built","Total Finished Living Area Sqft.","Census Tract and Block ID","Assessed Value of Structure","Zip Code","Total Property Tax","Total Tax Assessed Value of Parcel","Assessed Value of Land","Parcel ID","Log Error","Transaction Date","Total No. Baths","No. Bedrooms","FIPS Code","Longitude","Latitude","Zoning at County Level","Zoning","Description of Zoning","Census Tract and Block ID","County ID","Total No. Rooms","Asessment Year")

category<-c("buildingclasstypeid","finishedsquarefeet13","basementsqft","storytypeid","yardbuildingsqft26","fireplaceflag","architecturalstyletypeid","typeconstructiontypeid","finishedsquarefeet6","decktypeid","poolsizesum","pooltypeid10","pooltypeid2","taxdelinquencyflag","taxdelinquencyyear","hashottuborspa","yardbuildingsqft17","finishedsquarefeet15","finishedfloor1squarefeet","finishedsquarefeet50","fireplacecnt","threequarterbathnbr","pooltypeid7","poolcnt","numberofstories","airconditioningtypeid","garagecarcnt","garagetotalsqft","regionidneighborhood","heatingorsystemtypeid","buildingqualitytypeid","unitcnt","lotsizesquarefeet","finishedsquarefeet12","regionidcity","calculatedbathnbr","fullbathcnt","yearbuilt","calculatedfinishedsquarefeet","censustractandblock","structuretaxvaluedollarcnt","regionidzip","taxamount","taxvaluedollarcnt","landtaxvaluedollarcnt","parcelid","logerror","transactiondate","bathroomcnt","bedroomcnt","fips","latitude","longitude","propertycountylandusecode","propertylandusetypeid","propertyzoningdesc","rawcensustractandblock","regionidcounty","roomcnt","assessmentyear")

var_key<-data.frame(category, label)

train_2016<-merge(train_2016,properties_2016,by="parcelid")
train_2016[,factor_vars]<-lapply(train_2016[,factor_vars],factor)
train_2016$parcelid<-as.character(train_2016$parcelid)
train_2016$transactionmonth<-str_match(as.character(train_2016$transactiondate), pattern = one_or_more(DGT) %R% "-" %R% capture(one_or_more(DGT)))[,2]

train_2017<-merge(train_2017,properties_2017,by="parcelid")
train_2017[,factor_vars]<-lapply(train_2017[,factor_vars],factor)
train_2017$parcelid<-as.character(train_2017$parcelid)
train_2017$transactionmonth<-str_match(as.character(train_2017$transactiondate), pattern = one_or_more(DGT) %R% "-" %R% capture(one_or_more(DGT)))[,2]
```


```{r}
#properties_2016_subset<-properties_2016[,c("parcelid",names(properties_2016)[str_detect(names(properties_2016),pattern="tax" %R% or("value","amount"))])]
#names(properties_2016_subset)<-c("parcelid",paste0(names(properties_2016_subset)[2:ncol(properties_2016_subset)],"_2016"))
#properties<-merge(properties_2017,properties_2016_subset,by="parcelid")
```

### Missingness and Imputation

Calculate the missingness for each variable by counting the NA or empty string observations. Impute values based on other correlating variables.
```{r train_2016_missingness, include=FALSE}
# Count the number of NAs or empty strings in each column of properties_2016
missingness_2016_preimputation<-lapply(train_2016,function(x){
    ifelse(is.character(x),
          sum(str_detect(x,pattern=START %R% END)),
          sum(is.na(x))
  )
})

# Format missingness
missingness_2016_preimputation<-round(unlist(missingness_2016_preimputation)/nrow(train_2016)*100,3)
missingness_2016_preimputation<-sort(missingness_2016_preimputation,decreasing=T)
missingness_2016_preimputation<-as.data.frame(missingness_2016_preimputation)
missingness_2016_preimputation$var<-row.names(missingness_2016_preimputation)
row.names(missingness_2016_preimputation)<-seq(1:nrow(missingness_2016_preimputation))
missingness_2016_preimputation<-select(missingness_2016_preimputation,c("var","missingness_2016_preimputation"))
missingness_2016_preimputation<-missingness_2016_preimputation %>% mutate(category = lapply(missingness_2016_preimputation,function(x){if(x < 5){"<5%"} else if(x>=5 & x <= 95){">=5%, <=95%"} else{">95%"}}))
missingness_2016_preimputation$category<-as.character(missingness_2016_preimputation$category)

#p1 <- ggplot(missingness_2016_preimputation,aes(x=reorder(var, missingness_2016_preimputation),y=missingness_2016_preimputation,fill=category)) +
#  geom_col() +
#  scale_fill_manual(breaks=c(">95%",">=5%, <=95%","<5%"),values=c("blue","black","red")) +
#  scale_y_continuous(limits = c(NA,100),expand = c(0,0),breaks=c(0,25,50,75,99), labels=c("0","25","50","75","100")) +
#  theme_bw() +
#  theme(panel.grid = element_blank(),legend.position = c(0.9,0.1), axis.ticks=element_blank()) +
#  guides(fill=guide_legend(element_blank())) +
#  labs(y="Missingness (%)",x=element_blank()) +
#  scale_x_discrete(breaks=as.character(var_key$category), labels=as.character(var_key$label)) +
#  coord_flip()

#p1

#missingness_2017_preimputation<-lapply(train_2017,function(x){
#    ifelse(is.character(x),
#          sum(str_detect(x,pattern=START %R% END)),
#          sum(is.na(x))
#  )
#})

# Format missingness
#missingness_2017_preimputation<-round(unlist(missingness_2017_preimputation)/nrow(train_2017)*100,3)
#missingness_2017_preimputation<-sort(missingness_2017_preimputation,decreasing=T)
#missingness_2017_preimputation<-as.data.frame(missingness_2017_preimputation)
#missingness_2017_preimputation$var<-row.names(missingness_2017_preimputation)
#row.names(missingness_2017_preimputation)<-seq(1:nrow(missingness_2017_preimputation))
#missingness_2017_preimputation<-select(missingness_2017_preimputation,c("var","missingness_2017_preimputation"))
#missingness_2017_preimputation<-missingness_2017_preimputation %>% mutate(category = lapply(missingness_2017_preimputation,function(x){if(x < 5){"<5%"} else if(x>=5 & x <= 95){">=5%, <=95%"} else{">95%"}}))
#missingness_2017_preimputation$category<-as.character(missingness_2017_preimputation$category)

#p2 <- ggplot(missingness_2017_preimputation,aes(x=reorder(var, missingness_2017_preimputation),y=missingness_2017_preimputation,fill=category)) +
#  geom_col() +
#  scale_fill_manual(breaks=c(">95%",">=5%, <=95%","<5%"),values=c("blue","black","red")) +
#  scale_y_continuous(limits = c(NA,100),expand = c(0,0)) +
#  theme_bw() +
#  theme(panel.grid.major.x = element_blank(),legend.position = c(0.87,0.1),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), axis.ticks.x=element_blank()) +
#  guides(fill=guide_legend(element_blank())) +
#  labs(y="Missingness (%)",x=element_blank()) +
#  coord_flip()

#p2

names(missingness_2016_preimputation) <- c("var","missingness","category")
missingness_2016_preimputation$year<-factor(2016)
#names(missingness_2017_preimputation) <- c("var","missingness","category")
#missingness_2017_preimputation$year<-factor(2017)

#missingness<-rbind(missingness_2016_preimputation,missingness_2017_preimputation)

#ggplot(missingness) +
#  geom_col(aes(x=reorder(var,missingness),y=missingness,fill=year),position="dodge") +
#  coord_flip() +
#  scale_fill_brewer(palette = "Set1")

# Check if missingness is associated with logerror
character_variables<-names(which(sapply(train_2016, class) == "character")) # Get names of all columns whose entries are characters

tmp1<-as.data.frame(is.na(train_2016[,!(names(train_2016) %in% character_variables)])) # Check if NA for all columns whose entries are not characters
tmp2<-as.data.frame(lapply(train_2016[,names(train_2016) %in% character_variables],function(x){ 
  str_detect(x,pattern = START %R% END)
}))  # Check if empty string for all columns whose entries are characters
df_missing<-cbind(tmp1,tmp2)
df_missing<-sapply(df_missing,as.numeric)
colnames(df_missing)<-paste0(colnames(df_missing),"_missing")
df_missing<-as.data.frame(df_missing)
df_missing$parcelid<-train_2016$parcelid

cor_missing<-cor(df_missing[,-61])
cor_missing<-cor_missing[which(lapply(as.data.frame(df_missing[,-61]),sum) > 1),which(lapply(as.data.frame(df_missing[,-61]),sum) > 1)]

#p.mat<-cor_pmat(df_missing)
#tmp<-as.data.frame(p.mat)
#tmp[is.na(tmp)] <- 1
#p.mat<-as.matrix(tmp)

tmp<-cor_missing
tmp[lower.tri(cor_missing)] <- NA
tmp_melt<-melt(tmp)
tmp_melt<-tmp_melt[!is.na(tmp_melt$value),]
tmp2_melt<-melt(p.mat)
cor_mat<-merge(tmp_melt,tmp2_melt,by=c("Var1","Var2"),sort=F)
names(cor_mat)<-c("Var1","Var2","corr","pval")
cor_mat<-merge(cor_mat, var_key, by.x="Var1", by.y="category",sort=FALSE)
cor_mat<-merge(cor_mat, var_key, by.x="Var2", by.y="category",sort-FALSE)

ggplot(data =  cor_mat, aes(x =Var1, y = Var2)) +
  geom_tile(aes(fill = corr), colour = "white") +
  geom_text(aes(label = sprintf("%1.2f",round(corr,2)))) +
  scale_fill_gradient2(low="#377EB8", mid="white",high="#E41A1C") +
  scale_x_discrete(position="top",expand=c(0,0), breaks=var_key$category, labels=var_key$label) +
  scale_y_discrete(expand=c(0,0)) +
  theme(axis.title = element_blank(),axis.text.x=element_text(angle=45,vjust=0.5, hjust=0),axis.ticks = element_blank(),axis.line=element_blank())

cor_logerror_missing<-cor(df_missing,train_2016$logerror)
cor_logerror_missing<-cor_logerror_missing[!is.na(cor_logerror_missing),]
cor_logerror_missing<-as.data.frame(cor_logerror_missing)
cor_logerror_missing$type<-row.names(cor_logerror_missing)

p1<-ggplot(cor_logerror_missing,aes(x=reorder(type, abs(cor_logerror_missing)), y=abs(cor_logerror_missing),fill=ifelse(cor_logerror_missing < 0, "Negative","Positive"))) +
  geom_col() +
  scale_fill_brewer(palette = "Set1") +
  coord_flip() +
  guides(fill=guide_legend("Direction of\nCorrelation")) +
  labs(y= "Absolute Value of Correlation with Log Error", x="")

# Missingness of number of stories is fairly well associated with logerror for 2016 data

```

```{r distance_matrix, include=F}
imputed_train_2016<-train_2016

# Impute city based on zip and vice versa
# Will only work for cities and zips that are uniquely paired

# There are no entries that contain a neighborhood but /not/ a city or zip
# All entries have county id

region_table<-table(imputed_train_2016$regionidcity,imputed_train_2016$regionidzip)
melted_region_table<-melt(region_table)
names(melted_region_table)<-c("regionidcity","regionidzip","frequency")
melted_region_table<-melted_region_table[!(melted_region_table$frequency == 0),]
unique_cities<-names(which(table(melted_region_table$regionidcity) == 1)) # Cities that are uniquely associated with 1 zip code
city_key<-melted_region_table[melted_region_table$regionidcity %in% unique_cities,1:2] # Create a key to associate city with Zip
unique_zips<-names(which(table(melted_region_table$regionidzip) == 1)) # Zip codes that are uniquely associated with 1 city
zip_key<-melted_region_table[melted_region_table$regionidzip %in% unique_zips,1:2] # Create a key to associate Zip with city

# Check if there are entries that have zip but no city, and their zip is uniquely associated with one city
dim(imputed_train_2016[is.na(imputed_train_2016$regionidcity) & imputed_train_2016$regionidzip %in% unique_zips,]) # 472 entries have a zip code uniquely associated with 1 city, but no city data
m<-match(imputed_train_2016[is.na(imputed_train_2016$regionidcity) & imputed_train_2016$regionidzip %in% unique_zips,"regionidzip"],zip_key$regionidzip)
imputed_train_2016[is.na(imputed_train_2016$regionidcity) & imputed_train_2016$regionidzip %in% unique_zips,"regionidcity"] <- zip_key$regionidcity[m]

# Check if there are entries that have city but no zip, and their city is uniquely associated with one zip
dim(imputed_train_2016[is.na(imputed_train_2016$regionidzip) & imputed_train_2016$regionidcity %in% unique_cities,]) # 0 entries have a zip code uniquely associated with 1 city, but no city data
m<-match(imputed_train_2016[is.na(imputed_train_2016$regionidzip) & imputed_train_2016$regionidcity %in% unique_cities,"regionidcity"],city_key$regionidcity)
imputed_train_2016[is.na(imputed_train_2016$regionidzip) & imputed_train_2016$regionidcity %in% unique_cities,"regionidzip"] <- city_key$regionidzip[m]


# Use combination of city and zip to impute neighborhood
neighborhoods<-unique(imputed_train_2016[,c("regionidcity","regionidzip","regionidneighborhood")])
neighborhoods<-neighborhoods[!(is.na(neighborhoods$regionidcity) | is.na(neighborhoods$regionidzip) | is.na(neighborhoods$regionidneighborhood)),]
neighborhoods<-unite(neighborhoods,col="city_zip",regionidcity,regionidzip,sep=".")
neighborhoods$city_zip<-factor(neighborhoods$city_zip)

m<-match(
  as.factor(
    (imputed_train_2016 %>%
    dplyr::filter(!is.na(imputed_train_2016$regionidcity), !is.na(imputed_train_2016$regionidzip), is.na(imputed_train_2016$regionidneighborhood)) %>%
    unite("city_zip",regionidcity,regionidzip,sep=".") %>%
    dplyr::filter(city_zip %in% neighborhoods$city_zip) %>%
    as.data.frame())$city_zip),
  neighborhoods$city_zip
)

imputed_train_2016[!(is.na(imputed_train_2016$regionidcity) | is.na(imputed_train_2016$regionidzip)) & is.na(imputed_train_2016$regionidneighborhood) & (unite(imputed_train_2016,"city_zip",regionidcity,regionidzip,sep="."))$city_zip %in% neighborhoods$city_zip ,"regionidneighborhood"] <- neighborhoods$regionidneighborhood[m]

#Create distance matrix using latitude and longitude coordinates so that regional values may be imputed based on k nearest neighbors

coordinates<-train_2016[,c("longitude","latitude")]

coordinates$latitude<-as.numeric(str_replace(coordinates$latitude, pattern=capture(dgt(2)) %R% capture(one_or_more(DGT)),replacement=REF1 %R% DOT %R% REF2))
coordinates$longitude<-as.numeric(str_replace(coordinates$longitude, pattern=capture("-" %R% dgt(3)) %R% capture(one_or_more(DGT)),replacement=REF1 %R% DOT %R% REF2))

zip_na<-which(is.na(imputed_train_2016$regionidzip))

samples<-sample(which(!is.na(imputed_train_2016$regionidzip)),5000)

distance_mat<-matrix(NA, nrow=length(zip_na),ncol=length(samples))

for (i in 1:length(zip_na)){
  for (j in 1:length(samples)){
    distance_mat[i,j]<-
      sqrt((coordinates[zip_na[i],"latitude"] - coordinates[samples[j],"latitude"]) ** 2 + (coordinates[zip_na[i],"longitude"] - coordinates[samples[j],"longitude"]) ** 2)
 }
}

distance_mat<-as.data.frame(distance_mat)
names(distance_mat)<-samples
row.names(distance_mat)<-zip_na

# Impute zip based on coordinates, but ignore entries whose coordinates are not available

for(i in 1:length(zip_na)){
  if(!is.na(distance_mat[i,1])){
      imputed_train_2016[zip_na[i],"regionidzip"]<-
        factor(names(which.max(table(as.character(imputed_train_2016[names(sort(distance_mat[i,])[1:11]),"regionidzip"])))))
  }
}

# Impute 23 more city IDs by matching with unique zips
m<-match(imputed_train_2016[is.na(imputed_train_2016$regionidcity) & imputed_train_2016$regionidzip %in% unique_zips,"regionidzip"],zip_key$regionidzip)
imputed_train_2016[is.na(imputed_train_2016$regionidcity) & imputed_train_2016$regionidzip %in% unique_zips,"regionidcity"] <- zip_key$regionidcity[m]

# Impute the remaining 1004 missing city data by coordinates
city_na<-which(is.na(imputed_train_2016$regionidcity))

samples<-sample(which(!is.na(imputed_train_2016$regionidcity)),10000)

distance_mat<-matrix(NA, nrow=length(city_na),ncol=length(samples))

for (i in 1:length(city_na)){
  for (j in 1:length(samples)){
    distance_mat[i,j]<-
      sqrt((coordinates[city_na[i],"latitude"] - coordinates[samples[j],"latitude"]) ** 2 + (coordinates[city_na[i],"longitude"] - coordinates[samples[j],"longitude"]) ** 2)
 }
}

distance_mat<-as.data.frame(distance_mat)
names(distance_mat)<-samples

for(i in 1:length(city_na)){
  imputed_train_2016[city_na[i],"regionidcity"]<-factor(names(which.max(table(as.character(imputed_train_2016[names(sort(distance_mat[i,])[1:10]),"regionidcity"])))))
}
# All cities are imputed

m<-match(
  as.factor((imputed_train_2016 %>%
    dplyr::filter(!is.na(regionidcity), !is.na(regionidzip), is.na(regionidneighborhood)) %>%
    unite("city_zip",regionidcity,regionidzip,sep=".") %>%
    dplyr::filter(city_zip %in% neighborhoods$city_zip) %>%
    as.data.frame())$city_zip),
  neighborhoods$city_zip
)

imputed_train_2016[!(is.na(imputed_train_2016$regionidcity) | is.na(imputed_train_2016$regionidzip)) & is.na(imputed_train_2016$regionidneighborhood) & (unite(imputed_train_2016,"city_zip",regionidcity,regionidzip,sep="."))$city_zip %in% neighborhoods$city_zip ,"regionidneighborhood"] <- neighborhoods$regionidneighborhood[m]
```

```{r train_2016_imputation}
imputed_train_2016$taxdelinquencyflag <- ifelse(imputed_train_2016$taxdelinquencyflag == "Y",1,0)
imputed_train_2016[!is.na(imputed_train_2016$taxdelinquencyyear) & imputed_train_2016$taxdelinquencyyear == 0,"taxdelinquencyyear"] <- NA

imputed_train_2016[!is.na(imputed_train_2016$fireplacecnt),"fireplaceflag"]<-TRUE
imputed_train_2016[imputed_train_2016$fireplaceflag == "true","fireplaceflag"] <- TRUE
imputed_train_2016$fireplaceflag <- as.logical(imputed_train_2016$fireplaceflag)

imputed_train_2016[!is.na(imputed_train_2016$basementsqft),"basement"] <- TRUE
imputed_train_2016$basement<-as.logical(imputed_train_2016$basement)
imputed_train_2016<-imputed_train_2016[,!(names(imputed_train_2016) == "storytypeid")] # Only storytypeid is "basement" and completely overlaps with basementsqft values - created new value called "basement" that is logical and removing storytypeid

imputed_train_2016[!is.na(imputed_train_2016$poolcnt) | !is.na(imputed_train_2016$poolsizesum) | !is.na(imputed_train_2016$pooltypeid10) | !is.na(imputed_train_2016$pooltypeid2) | !is.na(imputed_train_2016$pooltypeid7),"pool"] <- 1
imputed_train_2016$pooltypeid10<-as.logical(ifelse(imputed_train_2016$pooltypeid10 == 1, 1, 0))
imputed_train_2016$pooltypeid7<-as.logical(ifelse(imputed_train_2016$pooltypeid7 == 1, 1, 0))
imputed_train_2016$pooltypeid2<-as.logical(ifelse(imputed_train_2016$pooltypeid2 == 1, 1, 0))

# Impute unit count based on propertly land use type ID
imputed_train_2016[imputed_train_2016$propertylandusetypeid == 246 & is.na(imputed_train_2016$unitcnt),"unitcnt"]<-2
imputed_train_2016[imputed_train_2016$propertylandusetypeid == 247 & is.na(imputed_train_2016$unitcnt),"unitcnt"]<-3
imputed_train_2016[imputed_train_2016$propertylandusetypeid == 248 & is.na(imputed_train_2016$unitcnt),"unitcnt"]<-4
```

```{r train_2016_recalculate_missingness,}
missingness<-lapply(imputed_train_2016,function(x){
    ifelse(is.character(x),
          sum(str_detect(x,pattern=START %R% END)),
          sum(is.na(x))
  )
})

# Format missingness
missingness<-as.numeric(missingness)
missingness<-as.data.frame(missingness)
missingness$var<-colnames(imputed_train_2016)
missingness<-missingness[order(missingness$missingness,decreasing=T),]
missingness$percent<-round(missingness$missingness/nrow(train_2016)*100,3)
row.names(missingness)<-seq(1:nrow(missingness))
missingness<-select(missingness,c("var","missingness","percent"))

missingness<-missingness %>% mutate(category = lapply(percent,function(x){if(x < 5){"<5%"} else if(x>=5 & x <= 95){">=5%, <=95%"} else{">95%"}}))
missingness$category<-as.character(missingness$category)
```

```{r echo=F}
p2 <- ggplot(missingness,aes(x=reorder(var, missingness),y=missingness,fill=category)) +
  geom_col() +
  scale_fill_manual(breaks=c(">95%",">=5%, <=95%","<5%"),values=c("blue","black","red")) +
  scale_y_continuous(limits = c(NA,100),expand = c(0,0)) +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),legend.position = c(0.87,0.1),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), axis.ticks.x=element_blank()) +
  guides(fill=guide_legend(element_blank())) +
  labs(y="Missingness (%)",x=element_blank()) +
  coord_flip()

p2
```

### Correlation

```{r correlation_after_imputation}
# calculate correlations of variables
numeric_vars<-names(which(lapply(imputed_train_2016,is.numeric) == TRUE))
#numeric_vars<-numeric_vars[numeric_vars %in% c(missingness[!(missingness$missingness == 0),"var"],"logerror")]
#numeric_vars<-numeric_vars[!(numeric_vars %in% c("basementsqft","finishedsquarefeet13","assessmentyear","finishedsquarefeet15","finishedsquarefeet6","threequarterbathnbr","unitcnt"))]
M <- cor(imputed_train_2016[,names(imputed_train_2016) %in% numeric_vars],use="pairwise.complete.obs")
tmp<-as.matrix(imputed_train_2016[,names(imputed_train_2016) %in% numeric_vars])
#M.pmat<-cor_pmat(tmp)
#M.pmat<-cor_pmat(imputed_train_2016[,names(imputed_train_2016) %in% numeric_vars])

tmp<-M
tmp[is.na(tmp)]=1000
tmp[lower.tri(M)] <- NA
tmp_melt<-melt(tmp)
tmp_melt<-tmp_melt[!is.na(tmp_melt$value),]
tmp_melt[tmp_melt$value==1000,"value"]<-NA
#tmp2_melt<-melt(p.mat)
#cor_mat<-merge(tmp_melt,tmp2_melt,by=c("Var1","Var2"),sort=F)
#names(cor_mat)<-c("Var1","Var2","corr","pval")
#cor_mat<-merge(cor_mat, var_key, by.x="Var1", by.y="category",sort=FALSE)
#cor_mat<-merge(cor_mat, var_key, by.x="Var2", by.y="category",sort-FALSE)


tmp_key<-var_key
tmp_key<-merge(var_key,missingness[,c("var","percent")],by.x="category", by.y="var")

ggplot(data =  tmp_melt, aes(x =Var1, y = Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  geom_text(aes(label = round(value,2))) +
  scale_fill_gradient2(low="#377EB8",mid="white", high="#E41A1C") +
  scale_x_discrete(position="top",expand=c(0,0), breaks=tmp_key$category, labels=paste(tmp_key$label," (",round(tmp_key$percent,2),"%)",sep="")) +
  scale_y_discrete(expand=c(0,0), breaks=tmp_key$category, labels=paste(tmp_key$label," (",round(tmp_key$percent,2),"%)",sep="")) +
  theme(axis.title = element_blank(),axis.text.x=element_text(angle=45,vjust=0.5, hjust=0),axis.ticks = element_blank(),axis.line=element_blank())
```

```{r}
ggplot(train_2016,aes(x=seq_along(logerror),y=logerror)) +
  geom_point() +
  geom_hline(yintercept = mean(train_2016$logerror) + 1.96*sd(train_2016$logerror)) +
  geom_hline(yintercept = mean(train_2016$logerror) - 1.96*sd(train_2016$logerror)) +
  theme_bw()

tails<-train_2016[train_2016$logerror > mean(train_2016$logerror) + 1.96*sd(train_2016$logerror) | train_2016$logerror < mean(train_2016$logerror) - 1.96*sd(train_2016$logerror),]

tails_missing<-df_missing[train_2016$logerror > mean(train_2016$logerror) + 1.96*sd(train_2016$logerror) | train_2016$logerror < mean(train_2016$logerror) - 1.96*sd(train_2016$logerror),]
cor_tails_missing<-cor(tails$logerror,tails_missing[,-61])

tmp<-cor_tails_missing
tmp[is.na(tmp)]<-1000
tmp[lower.tri(tmp)] <- NA
tmp_melt<-melt(tmp)
tmp_melt<-tmp_melt[!is.na(tmp_melt$value),]
tmp_melt[tmp_melt == 1000]<-NA

ggplot(data =  tmp_melt, aes(x =Var1, y = Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  geom_text(aes(label = sprintf("%1.2f",round(value)))) +
  scale_fill_gradient2(low="#377EB8", mid="white",high="#E41A1C") +
  scale_x_discrete(position="top",expand=c(0,0), breaks=var_key$category, labels=var_key$label) +
  scale_y_discrete(expand=c(0,0)) +
  theme(axis.title = element_blank(),axis.text.x=element_text(angle=45,vjust=0.5, hjust=0),axis.ticks = element_blank(),axis.line=element_blank())
# Missingness is not correlated with logerror in the tails of the logerror distribution

cor_tails<-cor(tails$logerror,tails[,names(tails) %in% numeric_vars & !(names(tails) == "logerror")])
tmp<-cor_tails
tmp[is.na(tmp)]<-1000
tmp[lower.tri(tmp)] <- NA
tmp_melt<-melt(tmp)
tmp_melt<-tmp_melt[!is.na(tmp_melt$value),]
tmp_melt[tmp_melt == 1000]<-NA
#tmp2_melt<-melt(p.mat)
#cor_mat<-merge(tmp_melt,tmp2_melt,by=c("Var1","Var2"),sort=F)
#names(cor_mat)<-c("Var1","Var2","corr","pval")
#cor_mat<-merge(cor_mat, var_key, by.x="Var1", by.y="category",sort=FALSE)
#cor_mat<-merge(cor_mat, var_key, by.x="Var2", by.y="category",sort-FALSE)

tmp_melt[is.na(tmp_melt$value),"Var2"]
for(i in as.character(tmp_melt[is.na(tmp_melt$value),"Var2"])){
  tmp_melt[tmp_melt$Var2==i,"value"]<-cor(tails[!is.na(tails[i]),"logerror"],tails[!is.na(tails[i]),i])
}

ggplot(data =  tmp_melt, aes(x =Var1, y = Var2)) +
  geom_tile(aes(fill = value), colour = "white") +
  geom_text(aes(label = sprintf("%1.2f",round(value,3)))) +
  scale_fill_gradient2(low="#377EB8", mid="white",high="#E41A1C") +
  scale_x_discrete(position="top",expand=c(0,0), breaks=var_key$category, labels=var_key$label) +
  scale_y_discrete(expand=c(0,0)) +
  theme(axis.title = element_blank(),axis.text.x=element_text(angle=45,vjust=0.5, hjust=0),axis.ticks = element_blank(),axis.line=element_blank())
```

```{r train_2017}
tmp1<-as.data.frame(is.na(train_2017[,!(names(train_2017) %in% character_variables)])) # Check if NA for all columns whose entries are not characters
tmp2<-as.data.frame(lapply(train_2017[,names(train_2017) %in% character_variables],function(x){ 
  str_detect(x,pattern = START %R% END)
}))  # Check if empty string for all columns whose entries are characters
df_missing_2017<-cbind(tmp1,tmp2)
df_missing_2017<-sapply(df_missing_2017,as.numeric)
colnames(df_missing_2017)<-paste0(colnames(df_missing_2017),"_missing")
df_missing_2017<-as.data.frame(df_missing_2017)
df_missing_2017$parcelid<-train_2017$parcelid
```

```{r distance_matrix, include=F}
imputed_train_2017<-train_2017

imputed_train_2017$taxdelinquencyflag <- ifelse(imputed_train_2017$taxdelinquencyflag == "Y",1,0)
imputed_train_2017[!is.na(imputed_train_2017$taxdelinquencyyear) & imputed_train_2017$taxdelinquencyyear == 0,"taxdelinquencyyear"] <- NA

imputed_train_2017[!is.na(imputed_train_2017$fireplacecnt),"fireplaceflag"]<-TRUE
imputed_train_2017[imputed_train_2017$fireplaceflag == "true","fireplaceflag"] <- TRUE
imputed_train_2017$fireplaceflag <- as.logical(imputed_train_2017$fireplaceflag)

imputed_train_2017[!is.na(imputed_train_2017$basementsqft),"basement"] <- TRUE
imputed_train_2017$basement<-as.logical(imputed_train_2017$basement)
imputed_train_2017<-imputed_train_2017[,!(names(imputed_train_2017) == "storytypeid")] # Only storytypeid is "basement" and completely overlaps with basementsqft values - created new value called "basement" that is logical and removing storytypeid

imputed_train_2017[!is.na(imputed_train_2017$poolcnt) | !is.na(imputed_train_2017$poolsizesum) | !is.na(imputed_train_2017$pooltypeid10) | !is.na(imputed_train_2017$pooltypeid2) | !is.na(imputed_train_2017$pooltypeid7),"pool"] <- 1
imputed_train_2017$pooltypeid10<-as.logical(ifelse(imputed_train_2017$pooltypeid10 == 1, 1, 0))
imputed_train_2017$pooltypeid7<-as.logical(ifelse(imputed_train_2017$pooltypeid7 == 1, 1, 0))
imputed_train_2017$pooltypeid2<-as.logical(ifelse(imputed_train_2017$pooltypeid2 == 1, 1, 0))

# Impute unit count based on propertly land use type ID
imputed_train_2017[!(is.na(imputed_train_2017$propertylandusetypeid)) & imputed_train_2017$propertylandusetypeid == 246 & is.na(imputed_train_2017$unitcnt),"unitcnt"]<-2
imputed_train_2017[!(is.na(imputed_train_2017$propertylandusetypeid)) & imputed_train_2017$propertylandusetypeid == 247 & is.na(imputed_train_2017$unitcnt),"unitcnt"]<-3
imputed_train_2017[!(is.na(imputed_train_2017$propertylandusetypeid)) & imputed_train_2017$propertylandusetypeid == 248 & is.na(imputed_train_2017$unitcnt),"unitcnt"]<-4
```
