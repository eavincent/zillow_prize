---
title: "Project Plan for the Zillow Prize"
author: "Liz Vincent"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document 
---

## Overview of Competition
The [Zillow prize competition](https://www.kaggle.com/c/zillow-prize-1): In this million-dollar competition, participants will develop an algorithm that makes predictions about the future sale prices of homes. The contest is structured into two rounds, the qualifying round which opens May 24, 2017 and the private round for the 100 top qualifying teams that opens on Feb 1st, 2018. In the qualifying round, you’ll be building a model to improve the Zestimate residual error. In the final round, you’ll build a home valuation algorithm from the ground up, using external data sources to help engineer new features that give your model an edge over the competition.

In this competition, Zillow is asking you to predict the log-error between their Zestimate and the actual sale price, given all the features of a home. The log error is defined as

*logerror=log(Zestimate)-log(SalePrice)*

and it is recorded in the transactions file *train.csv*. In this competition, you are going to predict the logerror for the months in Fall 2017. Since all the real estate transactions in the U.S. are publicly available, we will close the competition (no longer accepting submissions) before the evaluation period begins.

## Project Plan
### Choose Either Python or R
Python appears to be the language of choice for the kagglers in this competition, but I am not very familiar with Python. Choice depends mostly on time restrictions - is there time to learn Python *and* machine learning in time to create a reasonable algorithm?

### Learn Machine Learning
1. Complete machine learning courses on [DataCamp](https://www.datacamp.com/home)
    * Skill track for machine learning in [R](https://www.datacamp.com/tracks/machine-learning) (16hrs) **in progress**
2. Go through [Titanic tutorial](https://www.kaggle.com/c/titanic) on Kaggle

### Import and Explore Data
Become familiar with the format and general structure of the data.

* Check if missingness correlates with logerror **done**
* Check if missingness of variables correlates with each other **done**
* Check if logerror correlates with any of the variables
    + Requires converting or limiting to numeric variables

### Clean Data
Determine how to handle missing data and confirm that the classification methods are consistent for all entries (e.g. are bathrooms included in the total number of rooms?)

* cbind missingness data to training data _before_ imputation
* Impute variables from information in other variables 
    + Impute fireplaceflag by fireplacecnt
    + Impute missing data as negative response for taxdelinquency flag
    + Impute taxdelinquency year based on tax delinquency flag and vice versa
    + Impute pool info between the pool variables
    + Impute zip by city and vice versa for cities and zips that are uniquely associated
    + Finish imputing zip and city via latitude/longitude coordinates
    
### Begin Building Algorithm
* Predict the mean as a baseline
* Use linear model as secondary baseline
* Random forest

## To-do:
* Tidy training data
    + Handle categorical variables
    + Handle missing data - either throw it out or impute
    + Create a column for "imputed" in case of non-random missingness
* Subset training data into train and test
* Use linear modelas the baseline - whatever your machine learning algorithm is should do better than a linear model
    + Compare to predict by the mean (i.e. predict the mean for every observation) - if the machine learning algorithm does worse than predicting by the mean, it's incorrect
* Upload code to Kaggle and make public so that code is reproducible for instructors
* Try ggmap to map properties

Tables and figures:

* Plot missingness
* Make a table for RMSE and R^2 values to compare models 