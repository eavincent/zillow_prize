---
title: "Zillow Project Report"
author: "Liz Vincent"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F,message = F)

packages<-c("dplyr","ggplot2","magrittr","stringr","rebus","cowplot","caret","ranger","ggcorrplot","Matrix","data.table")

for (i in packages){
  if(!require(i,character.only = T,warn.conflicts = F)){
    install.packages(i,repos='http://cran.us.r-project.org')
  }
  require(i,character.only = T,warn.conflicts = F)
}
```

## 1. Import Data
```{r data_setup}
properties_2016<-read.csv("properties_2016.csv",stringsAsFactors = F)
properties_2017<-read.csv("properties_2017.csv",stringsAsFactors = F)
properties<-merge(properties_2017,properties_2016[,c("parcelid","structuretaxvaluedollarcnt","landtaxvaluedollarcnt","taxvaluedollarcnt","taxamount")],by="parcelid",suffixes = c("_2017","_2016"))
properties$parcelid<-as.character(properties$parcelid)

rm(properties_2016,properties_2017)

factor_vars <- c("airconditioningtypeid","architecturalstyletypeid","buildingclasstypeid","buildingqualitytypeid","decktypeid","heatingorsystemtypeid","propertylandusetypeid","regionidcity","regionidcounty","regionidneighborhood","regionidzip","storytypeid","typeconstructiontypeid","fips","propertycountylandusecode","propertyzoningdesc","rawcensustractandblock","censustractandblock")

properties[,factor_vars]<-lapply(properties[,factor_vars],factor)

label<-c("Framing Type","Perimeter Living Area Sqft.","Basement Sqft.","Type of Floors in Multi-Story House","Yard Building Sqft.","Fireplace, Y/N","Architecture Style","Construction Material","Unfinished and Finished Sqft.","Type of Deck","Pool Sqft.","Spa or Hot Tub, Y/N","Pool with Spa or Hot Tub, Y/N","Tax Delinquency, Y/N","Year of Tax Delinquency","Spa or Hot Tub, Y/N","Patio Sqft.","Total Sqft.","First Floor Living Area Sqft.","First Floor Living Area Sqft.","No. Fireplaces","No. 3/4 Baths","Pool without Spa or Hot Tub, Y/N","No. Pools","No. Stories","Type of Air Conditioning","No. Garages","Garage Sqft.","Neighborhood ID","Type of Heating System","Building Condition","No. Units","Lot Sqft.","Total Finished Living Area Sqft.","City ID","Total No. Baths","No. Full Baths","Year Built","Total Finished Living Area Sqft.","Census Tract and Block ID","Zip Code","Parcel ID","Log Error","Transaction Date","Total No. Baths","No. Bedrooms","FIPS Code","Longitude","Latitude","Zoning at County Level","Zoning","Description of Zoning","Census Tract and Block ID","County ID","Total No. Rooms","Asessment Year","Assessed Value of Structure","Total Property Tax","Total Tax Assessed Value of Parcel","Assessed Value of Land","County ID 1286","County ID 2061","County ID 3101","Month of Sale","Year of Sale")

category<-c("buildingclasstypeid","finishedsquarefeet13","basementsqft","storytypeid","yardbuildingsqft26","fireplaceflag","architecturalstyletypeid","typeconstructiontypeid","finishedsquarefeet6","decktypeid","poolsizesum","pooltypeid10","pooltypeid2","taxdelinquencyflag","taxdelinquencyyear","hashottuborspa","yardbuildingsqft17","finishedsquarefeet15","finishedfloor1squarefeet","finishedsquarefeet50","fireplacecnt","threequarterbathnbr","pooltypeid7","poolcnt","numberofstories","airconditioningtypeid","garagecarcnt","garagetotalsqft","regionidneighborhood","heatingorsystemtypeid","buildingqualitytypeid","unitcnt","lotsizesquarefeet","finishedsquarefeet12","regionidcity","calculatedbathnbr","fullbathcnt","yearbuilt","calculatedfinishedsquarefeet","censustractandblock","regionidzip","parcelid","logerror","transactiondate","bathroomcnt","bedroomcnt","fips","latitude","longitude","propertycountylandusecode","propertylandusetypeid","propertyzoningdesc","rawcensustractandblock","regionidcounty","roomcnt","assessmentyear","structuretaxvaluedollarcnt","taxamount","taxvaluedollarcnt","landtaxvaluedollarcnt","regionidcounty_1286","regionidcounty_2061","regionidcounty_3101","transactionmonth","transactionyear")

var_key<-data.frame(category, label)

character_variables<-names(which(sapply(properties, class) == "character"))

train_2016<-read.csv("train_2016_v2.csv")
train_2017<-read.csv("train_2017.csv")

train_2016<-merge(train_2016,properties[,c("parcelid","taxvaluedollarcnt_2016","landtaxvaluedollarcnt_2016","taxamount_2016","structuretaxvaluedollarcnt_2016")],by="parcelid")
names(train_2016) <- c("parcelid","logerror","transactiondate","taxvaluedollarcnt","landtaxvaluedollarcnt","taxamount","structuretaxvaluedollarcnt")

train_2017<-merge(train_2017,properties[,c("parcelid","taxvaluedollarcnt_2017","landtaxvaluedollarcnt_2017","taxamount_2017","structuretaxvaluedollarcnt_2017")],by="parcelid")
names(train_2017) <- c("parcelid","logerror","transactiondate","taxvaluedollarcnt","landtaxvaluedollarcnt","taxamount","structuretaxvaluedollarcnt")

train<-rbind(train_2016,train_2017)
train$transactionyear<-str_match(as.character(train$transactiondate), pattern = capture(one_or_more(DGT)) %R% "-")[,2]
train$transactionmonth<-str_match(as.character(train$transactiondate), pattern = one_or_more(DGT) %R% "-" %R% capture(one_or_more(DGT)))[,2]
train$parcelid<-as.character(train$parcelid)
train<-merge(train,properties[,!str_detect(names(properties),pattern="tax" %R% or("value","amount"))],by="parcelid")

properties<-train

rm(train_2016, train_2017,train)
```

## 2. Exploratory Data Analysis
```{r distribution_of_logerror, include = FALSE}
ggplot(properties[order(properties$logerror),]) +
  geom_boxplot(aes(y=logerror,x=1)) +
  theme_bw() +
  theme(panel.grid.major.y = element_blank(),panel.grid.minor = element_blank(), axis.text.y = element_blank(),axis.ticks.y=element_blank(), axis.title.y=element_blank()) +
  scale_y_continuous(limits = c(-5.5,5.5),breaks=seq(-5,5,by=1),name="Log Error") +
  coord_flip()
```

### 2.1 Calculate Missingness of Data
```{r properties_missingness, include=FALSE}
tmp1<-as.data.frame(is.na(properties[,!(names(properties) %in% character_variables)]))
tmp2<-as.data.frame(lapply(properties[,names(properties) %in% character_variables],function(x){ 
  str_detect(x,pattern = START %R% END)}))  

df_missing<-cbind(tmp1,tmp2)
df_missing<-sapply(df_missing,as.numeric)
colnames(df_missing)<-paste0(colnames(df_missing),"_missing")
df_missing<-as.data.frame(df_missing)
df_missing$parcelid<-properties$parcelid

rm(tmp1,tmp2)

# Count the number of NAs or empty strings in each column of properties_2016
num_missing<-lapply(df_missing[,!names(df_missing) %in% "parcelid"],sum)
percent<-lapply(num_missing,function(x){round(x/nrow(properties)*100,3)})
missingness<-cbind(num_missing,percent)
missingness<-as.data.frame(missingness)
missingness$percent<-as.numeric(missingness$percent)
missingness$num_missing<-as.numeric(missingness$num_missing)
missingness$var<-unlist(strsplit(rownames(missingness),"_missing$"))
missingness<-missingness[order(missingness$num_missing,decreasing=T),]
row.names(missingness)<-seq(1:nrow(missingness))
missingness<-select(missingness,c("var","num_missing","percent"))
missingness<-missingness %>%  mutate(category = lapply(percent,function(x){ifelse(x>=95,">=95%","<95%")}))
missingness$category<-as.character(missingness$category)

p1 <- ggplot(missingness,aes(x=reorder(var, percent),y=percent,fill=category)) +
  geom_col() +
  scale_fill_manual(breaks=c(">=95%","<95%"),values=c("gray70","gray30")) +
  scale_y_continuous(limits = c(NA,100),expand = c(0,0)) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),panel.grid.major.y = element_blank(),legend.position = c(0.875,0.09), axis.ticks=element_blank(),plot.margin = unit(c(0.01,0.03,0.01,0), "null")) +
  guides(fill=guide_legend(title = "Missingness")) +
  labs(y="Missingness (%)",x=element_blank()) +
  scale_x_discrete(breaks=as.character(var_key$category), labels=as.character(var_key$label)) +
  coord_flip()
```

### 2.2 Clean Data
One-hot-encode factor and character variables, impute NAs as negative responses
```{r one-hot-encoding}
properties$taxdelinquencyflag <- ifelse(properties$taxdelinquencyflag == "Y",1,0)
properties[!is.na(properties$taxdelinquencyyear) & properties$taxdelinquencyyear == 0,"taxdelinquencyyear"] <- NA

properties$fireplaceflag<-ifelse(!is.na(properties$fireplacecnt) | properties$fireplaceflag == "true",1,0)

colnames(properties)[which(colnames(properties) == "storytypeid")]<-"basement" # Only storytypeid is "basement" and completely overlaps with basementsqft values - rename as "basement" and coerce to binary
properties$basement<-ifelse(is.na(properties$basement),0,1)

properties$pool<-ifelse(!is.na(properties$poolcnt) | !is.na(properties$poolsizesum) | !is.na(properties$pooltypeid10) | !is.na(properties$pooltypeid2) | !is.na(properties$pooltypeid7), 1,0)
properties$pooltypeid10<-ifelse(is.na(properties$pooltypeid10), 0, 1)
properties$pooltypeid7<-ifelse(is.na(properties$pooltypeid7), 0, 1)
properties$pooltypeid2<-ifelse(is.na(properties$pooltypeid2), 0, 1)
properties$hashottuborspa<-ifelse(properties$hashottuborspa=="true",1,0)

properties$regionidcounty_1286<-ifelse(properties$regionidcounty == 1286,1,0)
properties$regionidcounty_2061<-ifelse(properties$regionidcounty == 2061,1,0)
properties$regionidcounty_3101<-ifelse(properties$regionidcounty == 3101,1,0)
properties<-properties[,!(colnames(properties) == "regionidcounty")]
```

### 2.3 Recalculate Missingness After Cleaning
```{r recalculate_missingness}
tmp1<-as.data.frame(is.na(properties[,!(names(properties) %in% character_variables)]))
tmp2<-as.data.frame(lapply(properties[,names(properties) %in% character_variables],function(x){ 
  str_detect(x,pattern = START %R% END)}))  

tmp<-cbind(tmp1,tmp2)
tmp<-sapply(tmp,as.numeric)
colnames(tmp)<-paste0(colnames(tmp),"_missing")
tmp<-as.data.frame(tmp)
tmp$parcelid<-properties$parcelid

rm(tmp1,tmp2)

# Count the number of NAs or empty strings in each column of properties_2016
num_missing<-lapply(tmp[,!names(tmp) %in% "parcelid"],sum)
percent<-lapply(num_missing,function(x){round(x/nrow(properties)*100,3)})
missingness_postimputation<-cbind(num_missing,percent)
missingness_postimputation<-as.data.frame(missingness_postimputation)
missingness_postimputation$percent<-as.numeric(missingness_postimputation$percent)
missingness_postimputation$num_missing<-as.numeric(missingness_postimputation$num_missing)
missingness_postimputation$var<-unlist(strsplit(rownames(missingness_postimputation),"_missing$"))
missingness_postimputation<-missingness_postimputation[order(missingness_postimputation$num_missing,decreasing=T),]
row.names(missingness_postimputation)<-seq(1:nrow(missingness_postimputation))
missingness_postimputation<-select(missingness_postimputation,c("var","num_missing","percent"))
missingness_postimputation<-missingness_postimputation %>%  mutate(category = lapply(percent,function(x){ifelse(x>=99,">=99%","<99%")}))
missingness_postimputation$category<-as.character(missingness_postimputation$category)
```

### 2.4 Correlation Analysis
```{r correlation_analyses}
#Correlation of missingness with logerror
tmp<-merge(properties[,c("parcelid","logerror")],df_missing,by="parcelid" )
cor_logerror_missing<-cor(tmp[,3:ncol(tmp)],abs(tmp$logerror))
cor_logerror_missing<-cor_logerror_missing[!is.na(cor_logerror_missing),]
cor_logerror_missing<-as.data.frame(cor_logerror_missing)
cor_logerror_missing$type<-unlist(strsplit(rownames(cor_logerror_missing),"_missing$"))
cor_logerror_missing.pmat<-cor_pmat(cbind(tmp[,3:ncol(tmp)],abs(tmp$logerror)))
cor_logerror_missing<-merge(cor_logerror_missing,cor_logerror_missing.pmat[,"abs(tmp$logerror)"],by=0)
rownames(cor_logerror_missing)<-cor_logerror_missing[,1]
cor_logerror_missing<-cor_logerror_missing[,-1]
names(cor_logerror_missing)<-c("corr","type","pval")
cor_logerror_missing<-cor_logerror_missing[cor_logerror_missing$pval < 0.05,]

# Correlation of numeric values (after imputation and one-hot encoding) with logerror
numeric_vars<-names(which(lapply(properties,is.numeric) == TRUE))
numeric_vars<-numeric_vars[numeric_vars %in% missingness[(missingness$percent < 93.2),"var"]]
M <- cor(properties[,names(properties) %in% numeric_vars],abs(properties$logerror),use="pairwise.complete.obs")
M <- as.data.frame(M)
M.pmat<-cor_pmat(properties[,names(properties) %in% numeric_vars])
M$type<-rownames(M)
M<-merge(M,M.pmat[,"logerror"],by.x="type",by.y=0)
names(M)<-c("type","corr","pval")
M<-M[!(is.na(M$corr)),]
M<-M[M$pval < 0.05,]
M<-merge(M,missingness,by.x="type",by.y="var")
M<-M[!M$type == "logerror",]

p2 <- ggplot(M,aes(x=reorder(type, abs(corr)), y=abs(corr),fill=ifelse(corr < 0, "Negative","Positive"))) +
  geom_col() +
  scale_fill_manual(breaks=c("Positive","Negative"),values=c("gray30","gray70")) +
  scale_y_continuous(limits=c(NA,0.12),expand = c(0,0)) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),panel.grid.major.y = element_blank(),legend.position = c(0.95,0.13), axis.ticks=element_blank(),plot.margin = unit(c(0.01,0.03,0.01,0), "null")) +
  coord_flip() +
  guides(fill=guide_legend("Direction of\nCorrelation")) +
  scale_x_discrete(breaks=as.character(var_key$category), labels=as.character(var_key$label)) +
  labs(y= "Absolute Value of Correlation", x="")

pg<-plot_grid(p1, p2, ncol=2, labels=c("A", "B"))
pg
#save_plot("missingness.pdf", pg, base_height=8, base_width = 14)
```

### 2.5 Remove Features
Remove features that are redundant or are missing for at least 95% of the parcels
```{r remove_redundant_features}
redundant_features<-c("censustratandblock","finishedsquarefeet50","hashottuborspa","finishedsquarefeet12","calculatedbathnbr")
highly_missing_features<-missingness_postimputation[missingness_postimputation$percent >= 95,"var"]
remove_features<-c(redundant_features,highly_missing_features)

properties<-properties[,!names(properties) %in% remove_features]
df_missing<-df_missing[,!names(df_missing) %in% paste0(remove_features,"_missing")]
```

## 3. Predictive Modeling
Prepare data for modeling by selecting numeric variables that have little or no missing data. Impute any missing values as the median, then center and scale. Create a second dataset that includes the missingness matrix.
```{r linear_models}
# Select numeric features with little or no missing data
data<-properties[,names(properties) %in% c("lotsizesquarefeet","calculatedfinishedsquarefeet","bathroomcnt","yearbuilt","logerror","bedroomcnt","latitude","longitude","roomcnt")]

# Impute the median
for(i in 1:ncol(data)){
  data[is.na(data[[i]]),i]<-median(na.omit(data[,i]))
}

# Center and scale
scaled_data<-scale(data[,!names(data) == "logerror"],center=T, scale=T)

data<-cbind(data$logerror, scaled_data)

# Include missingness matrix
data_together<-cbind(data,df_missing[,!names(df_missing) %in% c("parcelid","logerror")])
```

### 3.1 Predict the Mean
```{r predict_mean}
train_MAE<-NA
test_MAE<-NA

# Cross-validate predicting by the mean by splitting the data 80/20 for train and test sets 10 times and averaging the train and test
# MAE over the 10 cross-validations

# Set a different seed for every iteration to randomly reorder the rows before selecting the top 80% of rows for the training set
for(i in 1:10){
  set.seed(i) 
  rows<-sample(1:nrow(properties),nrow(properties))
  scrambled_properties<-properties[rows,]
  split<-round(nrow(properties) * 0.80)
  train<-scrambled_properties[1:split,]
  test<-scrambled_properties[(split+1):nrow(properties),]

  train_MAE[i]<-sum(abs(mean(train$logerror) - train$logerror))/nrow(train)
  test_MAE[i]<-sum(abs(mean(train$logerror) - test$logerror))/nrow(test)
}
mean(train_MAE)
mean(test_MAE)

# By definition, R^2 = 0 for predicting the mean
```

### 3.2 Predict the Median
```{r predict_median}
train_MAE<-NA
test_MAE<-NA
rsquare<-NA

for(i in 1:10){
  set.seed(i)
  rows<-sample(1:nrow(properties),nrow(properties))
  scrambled_properties<-properties[rows,]
  split<-round(nrow(properties) * 0.80)
  train<-scrambled_properties[1:split,]
  test<-scrambled_properties[(split+1):nrow(properties),]

  train_MAE[i]<-sum(abs(median(train$logerror) - train$logerror))/nrow(train)
  test_MAE[i]<-sum(abs(median(train$logerror) - test$logerror))/nrow(test)
  rss<-sum((median(properties$logerror) - properties$logerror) ** 2)
  ss<-sum((properties$logerror - mean(properties$logerror)) ** 2)
  rsquare[i]<-1-rss/ss
}

mean(train_MAE)
mean(test_MAE)
mean(rsquare)
```

### 3.3 Generalized Linear Models
Train a model on just the numeric data - not including missingness
```{r glmnet}
# Set alpha - the degree of mixing between lasso (0) and ridge (1)
# Set lambda - the scale by which a model is penalized for the number of covariates (lasso) 
# or the absolute value of the coefficients (ridge)

myGrid <- expand.grid(
  alpha = 0.03,
  lambda = 0.04
)

set.seed(123)

model.glmnet <- train( 
  logerror~.,
  data,
  method = "glmnet",
  tuneGrid = myGrid,
  metric = "MAE",
  trControl = trainControl(
  method = "cv",
  number = 10,
  verboseIter = T
  )
)

pred<-predict(model.glmnet,data)

glmnet_preds<-(cbind(pred,properties$logerror))
glmnet_preds<-as.data.frame(glmnet_preds)
names(glmnet_preds)<-c("pred","logerror")

#ggplot(glmnet_preds,aes(x=logerror,y=pred)) + 
#  geom_point() +
#  geom_abline(slope=1)

sum(abs(glmnet_preds$pred - glmnet_preds$logerror))/nrow(glmnet_preds)
#0.069247

glmnet_fmla <- coef(model.glmnet$finalModel, model.glmnet$bestTune$lambda) # Get coefficients for the covariates
```

Train a model on the data that includes the missingness matrix
```{r glmnet_together}
# Set alpha and lambda again

myGrid <- expand.grid(
  alpha = 0.275,
  lambda = 0.005
)

set.seed(123)

model.glmnet_together<-train( 
  logerror~.,
  data_together,
  method = "glmnet",
  tuneGrid = myGrid,
  metric = "MAE",
  trControl = trainControl(
  method = "cv",
  number = 10,
  verboseIter = T
  )
)

pred<-predict(model.glmnet_together,data_together)

glmnet_together_preds<-(cbind(pred,properties$logerror))
glmnet_together_preds<-as.data.frame(glmnet_together_preds)
names(glmnet_together_preds)<-c("pred","logerror")

ggplot(glmnet_together_preds,aes(x=logerror,y=pred)) + 
  geom_point() +
  geom_abline(slope=1)

sum(abs(glmnet_together_preds$pred - glmnet_together_preds$logerror))/nrow(glmnet_together_preds)
#0.06918523

glmnet_together_fmla <- coef(model.glmnet_together$finalModel, model.glmnet_together$bestTune$lambda) # Get coefficients for the covariates
```
